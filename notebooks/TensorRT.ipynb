{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate TensorRT Engines from Tensorflow (UFF models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can import TensorRT and its parsers like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "from tensorrt.parsers import uffparser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also some common tools that are used with tensorrt typically. We use PyCUDA to handle the CUDA operations needed to allocate memory on your GPU and to transfer data to the GPU and results back to the CPU. We also use numpy as our primary method to store data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import numpy as np\n",
    "from random import randint # generate a random test case\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow #to show test case\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import uff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STARTER_LEARNING_RATE = 1e-4\n",
    "BATCH_SIZE = 10\n",
    "NUM_CLASSES = 10\n",
    "MAX_STEPS = 3000\n",
    "IMAGE_SIZE = 28\n",
    "IMAGE_PIXELS = IMAGE_SIZE ** 2\n",
    "OUTPUT_NAMES = [\"fc2/Relu\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we are padding our Conv2d layer. TensorRT expects symetric padding for layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def WeightsVariable(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.1, name='weights'))\n",
    "\n",
    "def BiasVariable(shape):\n",
    "    return tf.Variable(tf.constant(0.1, shape=shape, name='biases'))\n",
    "\n",
    "def Conv2d(x, W, b, strides=1):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    filter_size = W.get_shape().as_list()\n",
    "    pad_size = filter_size[0]//2\n",
    "    pad_mat = np.array([[0,0],[pad_size,pad_size],[pad_size,pad_size],[0,0]])\n",
    "    x = tf.pad(x, pad_mat)\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='VALID')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "def MaxPool2x2(x, k=2):\n",
    "    # MaxPool2D wrapper\n",
    "    pad_size = k//2\n",
    "    pad_mat = np.array([[0,0],[pad_size,pad_size],[pad_size,pad_size],[0,0]])\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='VALID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def network(images):\n",
    "    # Convolution 1\n",
    "    with tf.name_scope('conv1'):\n",
    "        weights = WeightsVariable([5,5,1,32])\n",
    "        biases = BiasVariable([32])\n",
    "        conv1 = tf.nn.relu(Conv2d(images, weights, biases))\n",
    "        pool1 = MaxPool2x2(conv1)\n",
    "\n",
    "    # Convolution 2\n",
    "    with tf.name_scope('conv2'):\n",
    "        weights = WeightsVariable([5,5,32,64])\n",
    "        biases = BiasVariable([64])\n",
    "        conv2 = tf.nn.relu(Conv2d(pool1, weights, biases))\n",
    "        pool2 = MaxPool2x2(conv2)\n",
    "        pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "\n",
    "    # Fully Connected 1\n",
    "    with tf.name_scope('fc1'):\n",
    "        weights = WeightsVariable([7 * 7 * 64, 1024])\n",
    "        biases = BiasVariable([1024])\n",
    "        fc1 = tf.nn.relu(tf.matmul(pool2_flat, weights) + biases)\n",
    "\n",
    "    # Fully Connected 2\n",
    "    with tf.name_scope('fc2'):\n",
    "        weights = WeightsVariable([1024, 10])\n",
    "        biases = BiasVariable([10])\n",
    "        fc2 = tf.nn.relu(tf.matmul(fc1, weights) + biases)\n",
    "\n",
    "    return fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_metrics(logits, labels):\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels,\n",
    "                                                                   logits=logits,\n",
    "                                                                   name='softmax')\n",
    "    return tf.reduce_mean(cross_entropy, name='softmax_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def training(loss):\n",
    "    tf.summary.scalar('loss', loss)\n",
    "    global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "    learning_rate = tf.train.exponential_decay(STARTER_LEARNING_RATE,\n",
    "                                               global_step,\n",
    "                                               100000,\n",
    "                                               0.75,\n",
    "                                               staircase=True)\n",
    "    tf.summary.scalar('learning_rate', learning_rate)\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, 0.9)\n",
    "    train_op = optimizer.minimize(loss, global_step=global_step)\n",
    "    return train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluation(logits, labels):\n",
    "    correct = tf.nn.in_top_k(logits, labels, 1)\n",
    "    return tf.reduce_sum(tf.cast(correct, tf.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_eval(sess,\n",
    "            eval_correct,\n",
    "            images_placeholder,\n",
    "            labels_placeholder,\n",
    "            data_set,\n",
    "            summary):\n",
    "\n",
    "    true_count = 0\n",
    "    steps_per_epoch = data_set.num_examples // BATCH_SIZE\n",
    "    num_examples = steps_per_epoch * BATCH_SIZE\n",
    "    for step in range(steps_per_epoch):\n",
    "        feed_dict = fill_feed_dict(data_set,\n",
    "                                   images_placeholder,\n",
    "                                   labels_placeholder)\n",
    "        log, correctness = sess.run([summary, eval_correct], feed_dict=feed_dict)\n",
    "        true_count += correctness\n",
    "    precision = float(true_count) / num_examples\n",
    "    tf.summary.scalar('precision', tf.constant(precision))\n",
    "    print('Num examples %d, Num Correct: %d Precision @ 1: %0.04f' %\n",
    "          (num_examples, true_count, precision))\n",
    "    return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def placeholder_inputs(batch_size):\n",
    "    images_placeholder = tf.placeholder(tf.float32, shape=(None, 28, 28, 1))\n",
    "    labels_placeholder = tf.placeholder(tf.int32, shape=(None))\n",
    "    return images_placeholder, labels_placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fill_feed_dict(data_set, images_pl, labels_pl):\n",
    "    images_feed, labels_feed = data_set.next_batch(BATCH_SIZE)\n",
    "    feed_dict = {\n",
    "        images_pl: np.reshape(images_feed, (-1,28,28,1)),\n",
    "        labels_pl: labels_feed,\n",
    "    }\n",
    "    return feed_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and froze boi!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_training(data_sets):\n",
    "    with tf.Graph().as_default():\n",
    "        images_placeholder, labels_placeholder = placeholder_inputs(BATCH_SIZE)\n",
    "        logits = network(images_placeholder)\n",
    "        loss = loss_metrics(logits, labels_placeholder)\n",
    "        train_op = training(loss)\n",
    "        eval_correct = evaluation(logits, labels_placeholder)\n",
    "        summary = tf.summary.merge_all()\n",
    "        init = tf.global_variables_initializer()\n",
    "        saver = tf.train.Saver()\n",
    "        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.5)\n",
    "        sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "        summary_writer = tf.summary.FileWriter(\"/tmp/tensorflow/mnist/log\",\n",
    "                                               graph=tf.get_default_graph())\n",
    "        test_writer = tf.summary.FileWriter(\"/tmp/tensorflow/mnist/log/validation\",\n",
    "                                            graph=tf.get_default_graph())\n",
    "        sess.run(init)\n",
    "        for step in range(MAX_STEPS):\n",
    "            start_time = time.time()\n",
    "            feed_dict = fill_feed_dict(data_sets.train,\n",
    "                                       images_placeholder,\n",
    "                                       labels_placeholder)\n",
    "            _, loss_value = sess.run([train_op, loss], feed_dict=feed_dict)\n",
    "            duration = time.time() - start_time\n",
    "            if step % 100 == 0:\n",
    "                print('Step %d: loss = %.2f (%.3f sec)' % (step, loss_value, duration))\n",
    "                summary_str = sess.run(summary, feed_dict=feed_dict)\n",
    "                summary_writer.add_summary(summary_str, step)\n",
    "                summary_writer.flush()\n",
    "            if (step + 1) % 1000 == 0 or (step + 1) == MAX_STEPS:\n",
    "                checkpoint_file = os.path.join(\"/tmp/tensorflow/mnist/log\", \"model.ckpt\")\n",
    "                saver.save(sess, checkpoint_file, global_step=step)\n",
    "                print('Validation Data Eval:')\n",
    "                log = do_eval(sess,\n",
    "                              eval_correct,\n",
    "                              images_placeholder,\n",
    "                              labels_placeholder,\n",
    "                              data_sets.validation,\n",
    "                              summary)\n",
    "                test_writer.add_summary(log, step)\n",
    "        #return sess\n",
    "\n",
    "        graphdef = tf.get_default_graph().as_graph_def()\n",
    "        frozen_graph = tf.graph_util.convert_variables_to_constants(sess,\n",
    "                                                                    graphdef,\n",
    "                                                                    OUTPUT_NAMES)\n",
    "        return tf.graph_util.remove_training_nodes(frozen_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz\n",
      "Step 0: loss = 8.18 (3.224 sec)\n",
      "Step 100: loss = 2.34 (0.005 sec)\n",
      "Step 200: loss = 2.30 (0.005 sec)\n",
      "Step 300: loss = 1.96 (0.005 sec)\n",
      "Step 400: loss = 2.22 (0.005 sec)\n",
      "Step 500: loss = 1.88 (0.006 sec)\n",
      "Step 600: loss = 2.10 (0.005 sec)\n",
      "Step 700: loss = 2.31 (0.005 sec)\n",
      "Step 800: loss = 1.64 (0.005 sec)\n",
      "Step 900: loss = 2.00 (0.005 sec)\n",
      "Validation Data Eval:\n",
      "Num examples 5000, Num Correct: 4567 Precision @ 1: 0.9134\n",
      "Step 1000: loss = 2.05 (0.009 sec)\n",
      "Step 1100: loss = 1.75 (0.006 sec)\n",
      "Step 1200: loss = 1.65 (0.006 sec)\n",
      "Step 1300: loss = 1.27 (0.005 sec)\n",
      "Step 1400: loss = 2.14 (0.006 sec)\n",
      "Step 1500: loss = 1.62 (0.005 sec)\n",
      "Step 1600: loss = 2.07 (0.005 sec)\n",
      "Step 1700: loss = 2.30 (0.005 sec)\n",
      "Step 1800: loss = 2.07 (0.005 sec)\n",
      "Step 1900: loss = 1.41 (0.005 sec)\n",
      "Validation Data Eval:\n",
      "Num examples 5000, Num Correct: 4522 Precision @ 1: 0.9044\n",
      "Step 2000: loss = 1.26 (0.010 sec)\n",
      "Step 2100: loss = 1.65 (0.005 sec)\n",
      "Step 2200: loss = 2.30 (0.005 sec)\n",
      "Step 2300: loss = 1.68 (0.005 sec)\n",
      "Step 2400: loss = 1.28 (0.005 sec)\n",
      "Step 2500: loss = 1.64 (0.005 sec)\n",
      "Step 2600: loss = 1.43 (0.006 sec)\n",
      "Step 2700: loss = 1.86 (0.005 sec)\n",
      "Step 2800: loss = 2.09 (0.005 sec)\n",
      "Step 2900: loss = 1.66 (0.005 sec)\n",
      "Validation Data Eval:\n",
      "Num examples 5000, Num Correct: 4716 Precision @ 1: 0.9432\n",
      "INFO:tensorflow:Froze 8 variables.\n",
      "Converted 8 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "MNIST_DATASETS = input_data.read_data_sets('/tmp/tensorflow/mnist/input_data')\n",
    "tf_model = run_training(MNIST_DATASETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using output node fc2/Relu\n",
      "Converting to UFF graph\n",
      "No. nodes: 28\n"
     ]
    }
   ],
   "source": [
    "uff_model = uff.from_tensorflow(tf_model, [\"fc2/Relu\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G_LOGGER = trt.infer.ConsoleLogger(trt.infer.LogSeverity.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = uffparser.create_uff_parser()\n",
    "parser.register_input(\"Placeholder\", (1,28,28), 0)\n",
    "parser.register_output(\"fc2/Relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "engine = trt.utils.uff_to_trt_engine(G_LOGGER, uff_model, parser, 1, 1 << 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parser.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8628384b00>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8638222c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = MNIST_DATASETS.test.next_batch(1)\n",
    "img = img[0]\n",
    "#convert input data to Float32\n",
    "img = img.astype(np.float32)\n",
    "label = label[0]\n",
    "%matplotlib inline\n",
    "imshow(img.reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "runtime = trt.infer.create_infer_runtime(G_LOGGER)\n",
    "context = engine.create_execution_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = np.empty(10, dtype = np.float32)\n",
    "\n",
    "#alocate device memory\n",
    "d_input = cuda.mem_alloc(1 * img.size * img.dtype.itemsize)\n",
    "d_output = cuda.mem_alloc(1 * output.size * output.dtype.itemsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bindings = [int(d_input), int(d_output)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stream = cuda.Stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#transfer input data to device\n",
    "cuda.memcpy_htod_async(d_input, img, stream)\n",
    "#execute model\n",
    "context.enqueue(1, bindings, stream.handle, None)\n",
    "#transfer predictions back\n",
    "cuda.memcpy_dtoh_async(output, d_output, stream)\n",
    "#syncronize threads\n",
    "stream.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Case: 7\n",
      "Prediction: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Case: \" + str(label))\n",
    "print (\"Prediction: \" + str(np.argmax(output)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trt.utils.write_engine_to_file(\"./tf_mnist.engine\", engine.serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_engine = trt.utils.load_engine(G_LOGGER, \"./tf_mnist.engine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context.destroy()\n",
    "engine.destroy()\n",
    "new_engine.destroy()\n",
    "runtime.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
